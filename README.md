<p align="center">
  <h1 align="center"> Projeto de NLP: Classifica√ß√£o de Frases</h1>
  <p align="center">Classifica√ß√£o de frases <b>Adequadas</b> vs. <b>Potencialmente Violadoras</b> usando Logistic Regression (TF-IDF) e LSTM. </p>

  <!-- Badges principais -->
  <p align="center">
    <img src="https://img.shields.io/badge/python-3.12-blue?logo=python&logoColor=white" alt="Python Version">
    <img src="https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow&logoColor=white" alt="TensorFlow">
    <img src="https://img.shields.io/badge/Explainers-LIME%20%7C%20SHAP-green" alt="Explainability">
    <img src="https://img.shields.io/badge/status-educacional-lightgrey" alt="Status">
  </p>
</p>

<div align="center">

<img src="reports/nlp.jpeg" alt="Logo do Projeto" width="800"/>

</div>

---


# Processamento de Linguagem Natural (NLP)
Classificador de frases **Adequadas vs. Potencialmente Violadoras de Pol√≠ticas de Comunidade**, desenvolvido como estudo de **NLP aplicado √† modera√ß√£o de conte√∫do**.  
O projeto implementa modelo de **Deep Learning (LSTM)**, avaliando desempenho, m√©tricas e interpretabilidade com **LIME e SHAP**.

---

## üìå Objetivo
Demonstrar um pipeline completo de **Processamento de Linguagem Natural (NLP)**:
1. Coleta e constru√ß√£o de dataset seguro.
2. Pr√©-processamento (tokeniza√ß√£o, padding).
3. Treinamento de modelos avan√ßados (LSTM).
4. Avalia√ß√£o com m√©tricas cl√°ssicas e avan√ßadas.
5. Explicabilidade (LIME/SHAP) para interpreta√ß√£o de decis√µes.
6. Documenta√ß√£o √©tica sobre uso respons√°vel.

---

## üìÇ Estrutura do Projeto
```
NLP_Project/
‚îú‚îÄ‚îÄ notebooks/                    # Jupyter Notebooks com experimentos
‚îÇ ‚îú‚îÄ‚îÄ lstm_gru_classifier.ipynb
‚îÇ ‚îî‚îÄ‚îÄ explainability.ipynb
‚îú‚îÄ‚îÄ models/                      # Modelos treinados (.h5, .pt)
‚îú‚îÄ‚îÄ reports/                     # Gr√°ficos, m√©tricas e explica√ß√µes
‚îú‚îÄ‚îÄ README.md                    # Este arquivo
‚îî‚îÄ‚îÄ ETHICS.md                    # Documento de √©tica e boas pr√°ticas
```

---

## ‚öôÔ∏è Tecnologias Utilizadas
- **Linguagem:** Python 3.12  
- **Bibliotecas principais:**
  - `TensorFlow / Keras` (LSTM)
  - `scikit-learn` (TF-IDF, Logistic Regression, m√©tricas)
  - `LIME` e `SHAP` (explicabilidade)
  - `Matplotlib / Seaborn` (visualiza√ß√µes)

---

## üìä Dataset
- **Tamanho**: 1.020 frases  
- **Colunas**:
  - `frase` ‚Üí texto do coment√°rio
  - `label` ‚Üí 0 (Adequado), 1 (Violador)
- **Balanceamento**: classes equilibradas ‚úÖ
- **Exemplo**:
  | frase | label |
  |-------|-------|
  | "Seu trabalho ficou excelente, parab√©ns!" | 0 |
  | "Voc√™ s√≥ fala besteira, cala a boca" | 1 |

---

## ‚öôÔ∏è Pipeline do Projeto

1. **Explora√ß√£o de Dados (EDA)**  
   - Distribui√ß√£o de classes  
   - WordCloud das palavras mais comuns  

2. **Pr√©-processamento**  
   - Tokeniza√ß√£o  
   - Padroniza√ß√£o de sequ√™ncias  
   - Prepara√ß√£o para modelos cl√°ssicos e redes neurais  

3. **Modelagem**  
   - **Baseline**: Logistic Regression + TF-IDF  
   - **Deep Learning**: LSTM com embeddings  
   - Compara√ß√£o entre modelos  

4. **Avalia√ß√£o**  
   - M√©tricas: Accuracy, Precision, Recall, F1-score, ROC-AUC  
   - Visualiza√ß√µes: matriz de confus√£o, curvas ROC e Precision-Recall  

5. **Explicabilidade**  
   - **LIME**: destaca palavras-chave que impactam a predi√ß√£o  
   - **SHAP**: import√¢ncia global das features  

6. **Pipeline de Infer√™ncia**  
   - Fun√ß√£o para carregar modelo treinado e realizar predi√ß√£o em novas frases  

---

## üìà Resultados

|        Modelo                | Accuracy | F1-Score | ROC-AUC |
|------------------------------|----------|----------|---------|
| Logistic Regression (TF-IDF) |   0.86   |   0.85   |   0.90  |
| LSTM (Embedding)             |   0.89   |   0.88   |   0.92  |

- O modelo **LSTM** apresentou melhor desempenho.  
- Explicabilidade confirmou que termos ofensivos foram corretamente identificados como preditores de classe `1`.

---

## üìä Visualiza√ß√µes

### Avalia√ß√£o do Modelo (LSTM)

Para avaliar o desempenho do modelo LSTM, utilizamos a **Matriz de Confus√£o**, que mostra a quantidade de classifica√ß√µes corretas e incorretas:

- **Classe 0** ‚Üí Coment√°rios n√£o ofensivos  
- **Classe 1** ‚Üí Coment√°rios ofensivos  

Na figura abaixo:  
- üîµ Os quadrados escuros representam predi√ß√µes corretas.  
- ‚ö™ Os quadrados claros representam erros de classifica√ß√£o.  

![Matriz de Confus√£o - LSTM](./reports/matriz_confusao.jpeg)


### Interpreta√ß√£o do Modelo com LIME

Para entender como o modelo de NLP chega √†s suas previs√µes, utilizamos a t√©cnica **LIME (Local Interpretable Model-agnostic Explanations)**.  
Abaixo, um exemplo de explica√ß√£o para a frase *"Adoro participar das discuss√µes neste f√≥rum"*:

- As palavras destacadas em azul contribu√≠ram fortemente para a classifica√ß√£o como **Classe 0** (coment√°rio n√£o ofensivo).
- A probabilidade prevista foi de **98% para Classe 0** e **2% para Classe 1**.

![Explica√ß√£o LIME](./reports/html.jpeg)


---

## üõ°Ô∏è √âtica e Limita√ß√µes
> ‚ö†Ô∏è Este projeto tem **finalidade exclusivamente educacional**.

- Dataset **fict√≠cio e seguro** ‚Üí sem frases reais de √≥dio.  
- Modelos de NLP para modera√ß√£o **n√£o devem ser usados em produ√ß√£o sem revis√£o humana**.  
- Possibilidade de **falsos positivos** (moderar frases aceit√°veis) ou **falsos negativos** (n√£o detectar viola√ß√£o).  
- Explicabilidade (LIME/SHAP) usada para garantir **transpar√™ncia** das decis√µes.  

üìñ Detalhes adicionais em [ETHICS.md](./ETHICS.md)

---

## üöÄ Como Rodar

## Clonar reposit√≥rio
```
git clone https://github.com/seu-usuario/NLP_CommunityPolicyClassifier.git
cd NLP_CommunityPolicyClassifier
```

## Criar ambiente virtual
```
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

## Instalar depend√™ncias
```
pip install -r requirements.txt
```


## Pr√≥ximos Passos

- Testar outros modelos pr√©-treinados (RoBERTa, DistilBERT).

- Experimentar t√©cnicas de data augmentation para aumentar robustez.

- Deploy com FastAPI/Streamlit (apenas para demonstra√ß√£o com exemplos fict√≠cios).