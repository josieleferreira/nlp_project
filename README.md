<p align="center">
  <h1 align="center"> Community Policy Classifier</h1>
  <p align="center">Classifica√ß√£o de frases <b>Adequadas</b> vs. <b>Potencialmente Violadoras</b> usando LSTM, GRU e BERT</p>

  <!-- Badges principais -->
  <p align="center">
    <img src="https://img.shields.io/badge/python-3.12-blue?logo=python&logoColor=white" alt="Python Version">
    <img src="https://img.shields.io/badge/TensorFlow-2.x-orange?logo=tensorflow&logoColor=white" alt="TensorFlow">
    <img src="https://img.shields.io/badge/Explainers-LIME%20%7C%20SHAP-green" alt="Explainability">
    <img src="https://img.shields.io/badge/status-educacional-lightgrey" alt="Status">
  </p>
</p>

---


# üß† Community Policy Classifier
Classificador de frases **Adequadas vs. Potencialmente Violadoras de Pol√≠ticas de Comunidade**, desenvolvido como estudo de **NLP aplicado √† modera√ß√£o de conte√∫do**.  
O projeto implementa diferentes modelos de **Deep Learning (LSTM/GRU)** e **Transformers (BERT)**, avaliando desempenho, m√©tricas e interpretabilidade com **LIME e SHAP**.

---

## üìå Objetivo
Demonstrar um pipeline completo de **Processamento de Linguagem Natural (NLP)**:
1. Coleta e constru√ß√£o de dataset fict√≠cio e seguro.
2. Pr√©-processamento (tokeniza√ß√£o, padding).
3. Treinamento de modelos avan√ßados (LSTM, GRU, BERT).
4. Avalia√ß√£o com m√©tricas cl√°ssicas e avan√ßadas.
5. Explicabilidade (LIME/SHAP) para interpreta√ß√£o de decis√µes.
6. Documenta√ß√£o √©tica sobre uso respons√°vel.

---

## üìÇ Estrutura do Projeto
```
NLP_CommunityPolicyClassifier/
‚îú‚îÄ‚îÄ data/ # Dados fict√≠cios (CSV)
‚îú‚îÄ‚îÄ notebooks/ # Jupyter Notebooks com experimentos
‚îÇ ‚îú‚îÄ‚îÄ lstm_gru_classifier.ipynb
‚îÇ ‚îî‚îÄ‚îÄ explainability.ipynb
‚îú‚îÄ‚îÄ models/ # Modelos treinados (.h5, .pt)
‚îú‚îÄ‚îÄ reports/ # Gr√°ficos, m√©tricas e explica√ß√µes
‚îú‚îÄ‚îÄ src/ # C√≥digo modularizado
‚îÇ ‚îú‚îÄ‚îÄ preprocess.py
‚îÇ ‚îú‚îÄ‚îÄ train.py
‚îÇ ‚îú‚îÄ‚îÄ evaluate.py
‚îÇ ‚îî‚îÄ‚îÄ explain.py
‚îú‚îÄ‚îÄ README.md # Este arquivo
‚îî‚îÄ‚îÄ ETHICS.md # Documento de √©tica e boas pr√°ticas
```

---

## ‚öôÔ∏è Tecnologias Utilizadas
- **Linguagem:** Python 3.12  
- **Bibliotecas principais:**
  - `TensorFlow / Keras` (LSTM, GRU)
  - `scikit-learn` (m√©tricas)
  - `LIME` e `SHAP` (explicabilidade)
  - `Matplotlib / Seaborn` (visualiza√ß√µes)

---

## üîé Dataset Fict√≠cio
Criado manualmente para fins **did√°ticos**.  
Classes:
- `0 = Adequado`
- `1 = Potencial violador`

Exemplo:
| Frase | Label |
|-------|-------|
| "Seu trabalho ficou excelente, parab√©ns!" | 0 |
| "Voc√™ s√≥ fala besteira, cala a boca" | 1 |

---

## üìä Modelos Implementados

### üîπ LSTM / GRU (Keras)
- **Embedding + LSTM/GRU + Dense**  
- M√©tricas: Accuracy, Precision, Recall, F1, ROC-AUC  
- Explicabilidade: **LIME** (local) e **SHAP** (global)


---

## üìà Resultados

| Modelo   | Accuracy | Precision | Recall | F1 | AUC  | Tempo de Treino |
|----------|----------|-----------|--------|----|------|-----------------|
| **LSTM** | 0.90     | 0.91      | 0.89   | 0.90 | 0.92 | ~12s |
| **GRU**  | 0.88     | 0.89      | 0.87   | 0.88 | 0.91 | ~8s  |

*(valores ilustrativos, ajustar ap√≥s rodar no notebook)*

---

## üìä Visualiza√ß√µes

### Avalia√ß√£o do Modelo (LSTM)

Para avaliar o desempenho do modelo LSTM, utilizamos a **Matriz de Confus√£o**, que mostra a quantidade de classifica√ß√µes corretas e incorretas:

- **Classe 0** ‚Üí Coment√°rios n√£o ofensivos  
- **Classe 1** ‚Üí Coment√°rios ofensivos  

Na figura abaixo:  
- üîµ Os quadrados escuros representam predi√ß√µes corretas.  
- ‚ö™ Os quadrados claros representam erros de classifica√ß√£o.  

![Matriz de Confus√£o - LSTM](./reports/matriz_confusao.jpeg)


### Interpreta√ß√£o do Modelo com LIME

Para entender como o modelo de NLP chega √†s suas previs√µes, utilizamos a t√©cnica **LIME (Local Interpretable Model-agnostic Explanations)**.  
Abaixo, um exemplo de explica√ß√£o para a frase *"Adoro participar das discuss√µes neste f√≥rum"*:

- As palavras destacadas em azul contribu√≠ram fortemente para a classifica√ß√£o como **Classe 0** (coment√°rio n√£o ofensivo).
- A probabilidade prevista foi de **98% para Classe 0** e **2% para Classe 1**.

![Explica√ß√£o LIME](./reports/html.jpeg)


---

## üõ°Ô∏è √âtica e Limita√ß√µes
> ‚ö†Ô∏è Este projeto tem **finalidade exclusivamente educacional**.

- Dataset **fict√≠cio e seguro** ‚Üí sem frases reais de √≥dio.  
- Modelos de NLP para modera√ß√£o **n√£o devem ser usados em produ√ß√£o sem revis√£o humana**.  
- Possibilidade de **falsos positivos** (moderar frases aceit√°veis) ou **falsos negativos** (n√£o detectar viola√ß√£o).  
- Explicabilidade (LIME/SHAP) usada para garantir **transpar√™ncia** das decis√µes.  

üìñ Detalhes adicionais em [ETHICS.md](./ETHICS.md)

---

## üöÄ Como Rodar

# Clonar reposit√≥rio
```
git clone https://github.com/seu-usuario/NLP_CommunityPolicyClassifier.git
cd NLP_CommunityPolicyClassifier
```

# Criar ambiente virtual
```
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
.venv\Scripts\activate     # Windows
```

# Instalar depend√™ncias
```
pip install -r requirements.txt
```

# Rodar notebooks
```
jupyter notebook notebooks/lstm_gru_classifier.ipynb
```


Pr√≥ximos Passos

- Testar outros modelos pr√©-treinados (RoBERTa, DistilBERT).

- Experimentar t√©cnicas de data augmentation para aumentar robustez.

- Deploy com FastAPI/Streamlit (apenas para demonstra√ß√£o com exemplos fict√≠cios).